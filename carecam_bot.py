"""
Tá»· Tá»· CareCam - Full Automation Mode
=====================================

Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng hoÃ n toÃ n:
1. Camera mic thu Ã¢m â†’ App CareCam phÃ¡t qua speaker â†’ PC capture (WASAPI loopback)
2. AI xá»­ lÃ½ â†’ TTS â†’ PhÃ¡t qua Virtual Cable
3. App CareCam nháº­n tá»« Virtual Cable (nhÆ° mic) â†’ Camera speaker phÃ¡t

YÃŠU Cáº¦U:
- VB-Audio Virtual Cable: https://vb-audio.com/Cable/
- CÃ i Ä‘áº·t VB-Cable, sau Ä‘Ã³:
  1. Trong app CareCam: Settings â†’ Äá»•i Microphone thÃ nh "CABLE Output"
  2. Cháº¡y script nÃ y
"""

import sys
import os
import time
import threading
import tempfile
import wave
from typing import Optional

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    import pyaudio
    import numpy as np
except ImportError:
    print("Cáº§n cÃ i Ä‘áº·t: pip install pyaudio numpy")
    sys.exit(1)

from modules.ai_service import get_ai_service
from modules.text_to_speech import get_tts
from modules.speech_to_text import get_stt
from modules.wake_word import get_wake_detector
from config import config


class VirtualAudioPipeline:
    """Pipeline xá»­ lÃ½ audio tá»± Ä‘á»™ng vá»›i Virtual Cable"""
    
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.virtual_cable_input = None  # Index cá»§a "CABLE Input" (Ä‘á»ƒ phÃ¡t TTS)
        self.virtual_cable_output = None  # Index cá»§a "CABLE Output" (app dÃ¹ng lÃ m mic)
        self.default_output = None  # Default speaker
        
        self._find_devices()
    
    def _find_devices(self):
        """TÃ¬m cÃ¡c audio devices"""
        print("ğŸ” Äang tÃ¬m audio devices...")
        
        for i in range(self.audio.get_device_count()):
            dev = self.audio.get_device_info_by_index(i)
            name = dev['name'].lower()
            
            # TÃ¬m VB-Cable
            if 'cable input' in name and dev['maxOutputChannels'] > 0:
                self.virtual_cable_input = i
                print(f"   âœ… Found CABLE Input (output device): [{i}] {dev['name']}")
            
            if 'cable output' in name and dev['maxInputChannels'] > 0:
                self.virtual_cable_output = i
                print(f"   âœ… Found CABLE Output (input device): [{i}] {dev['name']}")
        
        # Default output
        try:
            self.default_output = self.audio.get_default_output_device_info()['index']
        except:
            self.default_output = 0
        
        if self.virtual_cable_input is None:
            print("\nâš ï¸  VB-Cable khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y!")
            print("   Táº£i táº¡i: https://vb-audio.com/Cable/")
            print("   CÃ i Ä‘áº·t xong, cháº¡y láº¡i script nÃ y.")
    
    def play_to_virtual_cable(self, audio_file: str) -> bool:
        """PhÃ¡t audio file qua Virtual Cable (Ä‘á»ƒ app CareCam nháº­n)"""
        if self.virtual_cable_input is None:
            print("âŒ VB-Cable chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t")
            return False
        
        try:
            wf = wave.open(audio_file, 'rb')
            
            stream = self.audio.open(
                format=self.audio.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=wf.getframerate(),
                output=True,
                output_device_index=self.virtual_cable_input
            )
            
            print(f"ğŸ“¤ PhÃ¡t qua Virtual Cable â†’ Camera speaker...")
            chunk = 1024
            data = wf.readframes(chunk)
            
            while data:
                stream.write(data)
                data = wf.readframes(chunk)
            
            stream.stop_stream()
            stream.close()
            wf.close()
            
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i phÃ¡t Virtual Cable: {e}")
            return False
    
    def play_to_speakers(self, audio_file: str) -> bool:
        """PhÃ¡t audio qua loa PC (Ä‘á»ƒ user nghe)"""
        try:
            wf = wave.open(audio_file, 'rb')
            
            stream = self.audio.open(
                format=self.audio.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=wf.getframerate(),
                output=True,
                output_device_index=self.default_output
            )
            
            chunk = 1024
            data = wf.readframes(chunk)
            
            while data:
                stream.write(data)
                data = wf.readframes(chunk)
            
            stream.stop_stream()
            stream.close()
            wf.close()
            
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i phÃ¡t speaker: {e}")
            return False
    
    def has_virtual_cable(self) -> bool:
        """Kiá»ƒm tra VB-Cable Ä‘Ã£ Ä‘Æ°á»£c cÃ i chÆ°a"""
        return self.virtual_cable_input is not None
    
    def close(self):
        self.audio.terminate()


class TyTyFullAutoBot:
    """Tá»· Tá»· chatbot vá»›i full automation qua CareCam"""
    
    def __init__(self):
        print("=" * 60)
        print("ğŸ¤– Tá»· Tá»· - CareCam Full Automation")
        print("=" * 60)
        print()
        
        self.pipeline = None
        self.ai = None
        self.tts = None
        self.stt = None
        self.detector = None
        self.running = False
    
    def initialize(self) -> bool:
        """Khá»Ÿi táº¡o táº¥t cáº£ components"""
        try:
            print("ğŸ”„ Äang khá»Ÿi táº¡o...\n")
            
            # Virtual Audio Pipeline
            self.pipeline = VirtualAudioPipeline()
            
            if not self.pipeline.has_virtual_cable():
                print("\n" + "=" * 60)
                print("âš ï¸  Cáº¦N CÃ€I Äáº¶T VB-CABLE!")
                print("=" * 60)
                print("\n1. Táº£i VB-Cable: https://vb-audio.com/Cable/")
                print("2. CÃ i Ä‘áº·t (cháº¡y VBCABLE_Setup_x64.exe vá»›i admin)")
                print("3. Trong app CareCam:")
                print("   - Click pháº£i vÃ o icon loa (taskbar)")
                print("   - Chá»n 'Open Sound settings'")
                print("   - App input: chá»n 'CABLE Output'")
                print("4. Cháº¡y láº¡i script nÃ y")
                print()
                
                # Váº«n cho cháº¡y vá»›i cháº¿ Ä‘á»™ manual
                print("ğŸ’¡ Tiáº¿p tá»¥c vá»›i cháº¿ Ä‘á»™ MANUAL (khÃ´ng tá»± Ä‘á»™ng phÃ¡t qua camera)")
                input("   Nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")
            
            # Speech-to-Text (tá»« default mic Náº¾U báº­t speaker trong app)
            self.stt = get_stt()
            
            # Wake word detector
            self.detector = get_wake_detector()
            
            # Text-to-Speech
            self.tts = get_tts()
            
            # AI service
            self.ai = get_ai_service()
            
            print("\n" + "=" * 60)
            print("âœ… Sáºµn sÃ ng! NÃ³i 'Tá»· Tá»·' vÃ o camera Ä‘á»ƒ báº¯t Ä‘áº§u")
            print("=" * 60)
            
            # Test connection - phÃ¡t "xin chÃ o" qua camera
            if self.pipeline.has_virtual_cable():
                self._say_to_camera("Xin chÃ o! Tá»· Tá»· Ä‘Ã£ káº¿t ná»‘i vá»›i camera.")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ Lá»—i khá»Ÿi táº¡o: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _say_to_camera(self, text: str):
        """PhÃ¡t text qua camera speaker (qua Virtual Cable)"""
        try:
            # Generate TTS to file
            import asyncio
            import edge_tts
            
            temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
            mp3_file = temp_file.name.replace(".wav", ".mp3")
            
            async def generate():
                communicate = edge_tts.Communicate(text, config.TTS_VOICE)
                await communicate.save(mp3_file)
            
            asyncio.run(generate())
            
            # Convert MP3 to WAV (for pyaudio)
            from pydub import AudioSegment
            audio = AudioSegment.from_mp3(mp3_file)
            audio.export(temp_file.name, format="wav")
            
            # Play to Virtual Cable
            self.pipeline.play_to_virtual_cable(temp_file.name)
            
            # Also play to local speaker so user can hear
            self.pipeline.play_to_speakers(temp_file.name)
            
            # Cleanup
            os.remove(mp3_file)
            os.remove(temp_file.name)
            
        except Exception as e:
            print(f"âŒ Lá»—i phÃ¡t audio: {e}")
    
    def _say_local(self, text: str):
        """PhÃ¡t text qua loa PC (khÃ´ng qua camera)"""
        self.tts.speak(text)
    
    def process_command(self, command: str) -> str:
        """Xá»­ lÃ½ command vÃ  tráº£ vá» response"""
        print(f"\nğŸ’­ Äang xá»­ lÃ½: '{command}'")
        response = self.ai.get_response(command)
        print(f"ğŸ¤– Tá»· Tá»·: {response}")
        return response
    
    def listen_loop(self):
        """Main loop láº¯ng nghe vÃ  pháº£n há»“i"""
        print("\nğŸ§ Äang láº¯ng nghe qua PC microphone...")
        print("ğŸ’¡ Trong app CareCam, báº­t loa (speaker) Ä‘á»ƒ PC cÃ³ thá»ƒ nghe camera")
        print("   NÃ³i 'Tá»· Tá»·' + cÃ¢u há»i vÃ o camera")
        print("   Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng\n")
        
        self.running = True
        
        while self.running:
            try:
                # Listen from default mic (should pick up app audio if speaker is on)
                text = self.stt.listen_and_recognize()
                
                if not text:
                    continue
                
                # Check wake word
                detected, command = self.detector.check(text)
                
                if detected:
                    if command:
                        response = self.process_command(command)
                        
                        if self.pipeline.has_virtual_cable():
                            self._say_to_camera(response)
                        else:
                            self._say_local(response)
                            print("ğŸ’¡ Giá»¯ nÃºt mic trong app Ä‘á»ƒ phÃ¡t qua camera!")
                    
                    elif self.detector.is_just_wake_word(text):
                        if self.pipeline.has_virtual_cable():
                            self._say_to_camera("Dáº¡, Tá»· Tá»· nghe Ä‘Ã¢y!")
                        else:
                            self._say_local("Dáº¡, Tá»· Tá»· nghe Ä‘Ã¢y!")
                        
                        print("ğŸ‘‚ Äá»£i cÃ¢u há»i...")
                        command = self.stt.listen_and_recognize()
                        
                        if command:
                            response = self.process_command(command)
                            if self.pipeline.has_virtual_cable():
                                self._say_to_camera(response)
                            else:
                                self._say_local(response)
                        else:
                            msg = "Tá»· Tá»· khÃ´ng nghe rÃµ. Báº¡n nÃ³i láº¡i nhÃ©!"
                            if self.pipeline.has_virtual_cable():
                                self._say_to_camera(msg)
                            else:
                                self._say_local(msg)
                else:
                    print(f"ğŸ‘€ Nghe: '{text}' (khÃ´ng cÃ³ wake word)")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ›‘ Äang dá»«ng...")
                self.running = False
                break
            except Exception as e:
                print(f"âŒ Lá»—i: {e}")
                continue
        
        if self.pipeline:
            self.pipeline.close()
    
    def run(self):
        """Start the bot"""
        if self.initialize():
            self.listen_loop()
        else:
            print("\nâŒ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng")


def main():
    bot = TyTyFullAutoBot()
    bot.run()


if __name__ == "__main__":
    main()
